{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8135a9-a8e9-4e5b-8a7b-2d3f6a4ffb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f7cdff-0e7f-4bc0-9c9a-bcbbf0f90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pq.read_table('./Data/cleaned_taxi_data.parquet')\n",
    "temp = temp.to_pandas()\n",
    "\n",
    "trip_inf_loc = list(range(0, 5)) + list(range(6, 172))\n",
    "tip_inf_loc = [172, 173, 174, 175] \n",
    "trip_info = torch.tensor(temp.iloc[:, trip_inf_loc].values)\n",
    "y = torch.tensor(temp.iloc[:, tip_inf_loc].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b1baed-8339-4f0b-935a-878be1f56c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97507d10-82d2-4ed5-bd0c-98fd88af464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and Split Input Data (Train = 75% (1,707,346), Validation = 20% (455,292), Test = 5% (113,823))\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trip_info,  [0.75, 0.2, 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d3b037-a3a4-4f12-a8ec-94c39550443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.linear_1.weight.size(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### MAKE SURE YOU CONNECT THE LAYERS PROPERLY IF YOU CHANGED\n",
    "        ### ANYTHNG IN THE __init__ METHOD ABOVE       \n",
    "        out = self.linear_1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = MLP(num_features=171,\n",
    "            num_hidden_1=100,\n",
    "            num_classes=4)\n",
    "\n",
    "\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "043a6e51-2c67-4fc0-b9d7-51b10856e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.9000,  5.0000,  3.0000,  0.5000,  0.0000,  0.3000, 11.0000,\n",
      "          2.5000,  0.0000,  0.2000,  1.0000,  0.0000, 13.0000,  1.0000,  0.0000,\n",
      "         17.0000, 67.4000, 49.9000, 56.5000,  5.8000, 30.2000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.dataset[0].view(-1, 171))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5c0623-069d-4b7f-aa50-d728a213f49d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (features, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     28\u001b[0m     \n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m### PREPARE MINIBATCH\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "train_acc_lst, valid_acc_lst = [], []\n",
    "train_loss_lst, valid_loss_lst = [], []\n",
    "#train_dataset, val_dataset, test_dataset, y\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(y.shape()[0]):\n",
    "        \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = train_dataset.dataset[i].view(-1, 171).to(DEVICE)\n",
    "        targets = y.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        #if not batch_idx % 20:\n",
    "        #    print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "        #           f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "        #           f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "        valid_acc, valid_loss = compute_accuracy_and_loss(model, valid_loader, device=DEVICE)\n",
    "        train_acc_lst.append(train_acc)\n",
    "        valid_acc_lst.append(valid_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
