{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8135a9-a8e9-4e5b-8a7b-2d3f6a4ffb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f7cdff-0e7f-4bc0-9c9a-bcbbf0f90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pq.read_table('./Data/cleaned_taxi_data.parquet')\n",
    "temp = temp.to_pandas()\n",
    "\n",
    "trip_info = torch.tensor(temp.values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbdbfa0-58eb-40bd-b607-999d4ae9480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>...</th>\n",
       "      <th>store_and_fwd_flag_0</th>\n",
       "      <th>store_and_fwd_flag_1</th>\n",
       "      <th>payment_type_1</th>\n",
       "      <th>payment_type_2</th>\n",
       "      <th>payment_type_3</th>\n",
       "      <th>payment_type_4</th>\n",
       "      <th>tip_bin_0</th>\n",
       "      <th>tip_bin_1</th>\n",
       "      <th>tip_bin_2</th>\n",
       "      <th>tip_bin_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "      <td>2.276461e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.472616e+00</td>\n",
       "      <td>2.017087e+00</td>\n",
       "      <td>9.898870e+00</td>\n",
       "      <td>1.023657e+00</td>\n",
       "      <td>4.994395e-01</td>\n",
       "      <td>1.966696e+00</td>\n",
       "      <td>4.196900e-03</td>\n",
       "      <td>2.999851e-01</td>\n",
       "      <td>1.543090e+01</td>\n",
       "      <td>2.434673e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.922112e-01</td>\n",
       "      <td>7.788844e-03</td>\n",
       "      <td>7.807847e-01</td>\n",
       "      <td>2.155697e-01</td>\n",
       "      <td>2.394945e-03</td>\n",
       "      <td>1.250625e-03</td>\n",
       "      <td>3.378955e-01</td>\n",
       "      <td>5.871385e-01</td>\n",
       "      <td>7.437246e-02</td>\n",
       "      <td>5.934650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.039033e+00</td>\n",
       "      <td>1.671309e+00</td>\n",
       "      <td>5.098086e+00</td>\n",
       "      <td>1.194539e+00</td>\n",
       "      <td>1.673157e-02</td>\n",
       "      <td>1.719994e+00</td>\n",
       "      <td>1.745916e-01</td>\n",
       "      <td>2.113585e-03</td>\n",
       "      <td>6.083246e+00</td>\n",
       "      <td>3.988098e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.791008e-02</td>\n",
       "      <td>8.791008e-02</td>\n",
       "      <td>4.137149e-01</td>\n",
       "      <td>4.112171e-01</td>\n",
       "      <td>4.887955e-02</td>\n",
       "      <td>3.534207e-02</td>\n",
       "      <td>4.729929e-01</td>\n",
       "      <td>4.923484e-01</td>\n",
       "      <td>2.623761e-01</td>\n",
       "      <td>2.435391e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.020000e+00</td>\n",
       "      <td>6.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.130000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.610000e+00</td>\n",
       "      <td>8.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.416000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.520000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.860000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.790000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>9.990000e+01</td>\n",
       "      <td>3.000000e+02</td>\n",
       "      <td>4.550000e+01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>3.500000e+02</td>\n",
       "      <td>2.620000e+01</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>3.573000e+02</td>\n",
       "      <td>2.750000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_count  trip_distance   fare_amount         extra  \\\n",
       "count     2.276461e+06   2.276461e+06  2.276461e+06  2.276461e+06   \n",
       "mean      1.472616e+00   2.017087e+00  9.898870e+00  1.023657e+00   \n",
       "std       1.039033e+00   1.671309e+00  5.098086e+00  1.194539e+00   \n",
       "min       1.000000e+00   1.000000e-02  0.000000e+00  0.000000e+00   \n",
       "25%       1.000000e+00   1.020000e+00  6.500000e+00  0.000000e+00   \n",
       "50%       1.000000e+00   1.610000e+00  8.500000e+00  5.000000e-01   \n",
       "75%       2.000000e+00   2.520000e+00  1.200000e+01  2.500000e+00   \n",
       "max       7.000000e+00   9.990000e+01  3.000000e+02  4.550000e+01   \n",
       "\n",
       "            mta_tax    tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "count  2.276461e+06  2.276461e+06  2.276461e+06           2.276461e+06   \n",
       "mean   4.994395e-01  1.966696e+00  4.196900e-03           2.999851e-01   \n",
       "std    1.673157e-02  1.719994e+00  1.745916e-01           2.113585e-03   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00           0.000000e+00   \n",
       "25%    5.000000e-01  8.000000e-01  0.000000e+00           3.000000e-01   \n",
       "50%    5.000000e-01  2.000000e+00  0.000000e+00           3.000000e-01   \n",
       "75%    5.000000e-01  2.860000e+00  0.000000e+00           3.000000e-01   \n",
       "max    5.000000e-01  3.500000e+02  2.620000e+01           3.000000e-01   \n",
       "\n",
       "       total_amount  congestion_surcharge  ...  store_and_fwd_flag_0  \\\n",
       "count  2.276461e+06          2.276461e+06  ...          2.276461e+06   \n",
       "mean   1.543090e+01          2.434673e+00  ...          9.922112e-01   \n",
       "std    6.083246e+00          3.988098e-01  ...          8.791008e-02   \n",
       "min    3.000000e-01          0.000000e+00  ...          0.000000e+00   \n",
       "25%    1.130000e+01          2.500000e+00  ...          1.000000e+00   \n",
       "50%    1.416000e+01          2.500000e+00  ...          1.000000e+00   \n",
       "75%    1.790000e+01          2.500000e+00  ...          1.000000e+00   \n",
       "max    3.573000e+02          2.750000e+00  ...          1.000000e+00   \n",
       "\n",
       "       store_and_fwd_flag_1  payment_type_1  payment_type_2  payment_type_3  \\\n",
       "count          2.276461e+06    2.276461e+06    2.276461e+06    2.276461e+06   \n",
       "mean           7.788844e-03    7.807847e-01    2.155697e-01    2.394945e-03   \n",
       "std            8.791008e-02    4.137149e-01    4.112171e-01    4.887955e-02   \n",
       "min            0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%            0.000000e+00    1.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%            0.000000e+00    1.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%            0.000000e+00    1.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max            1.000000e+00    1.000000e+00    1.000000e+00    1.000000e+00   \n",
       "\n",
       "       payment_type_4     tip_bin_0     tip_bin_1     tip_bin_2     tip_bin_3  \n",
       "count    2.276461e+06  2.276461e+06  2.276461e+06  2.276461e+06  2.276461e+06  \n",
       "mean     1.250625e-03  3.378955e-01  5.871385e-01  7.437246e-02  5.934650e-04  \n",
       "std      3.534207e-02  4.729929e-01  4.923484e-01  2.623761e-01  2.435391e-02  \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%      0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%      0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "\n",
       "[8 rows x 176 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b1baed-8339-4f0b-935a-878be1f56c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97507d10-82d2-4ed5-bd0c-98fd88af464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and Split Input Data (Train = 75% (1,707,346), Validation = 20% (455,292), Test = 5% (113,823))\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(trip_info,  [0.75, 0.2, 0.05])\n",
    "\n",
    "trip_inf_loc = list(range(0, 5)) + list(range(6, 172))\n",
    "tip_inf_loc = [172, 173, 174, 175]\n",
    "x = train_dataset.dataset[:, trip_inf_loc]\n",
    "y = train_dataset.dataset[:, tip_inf_loc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd9778b-ec4a-4702-9dae-1471c6f1d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2276461, 109])\n",
      "torch.Size([2276461, 67])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d3b037-a3a4-4f12-a8ec-94c39550443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.linear_1.weight.size(0))\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_1, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         \n",
    "        out = self.linear_1(x)\n",
    "        print(out.shape)\n",
    "        print(self.linear_1.weight.size(0))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "#################################\n",
    "### Model Initialization\n",
    "#################################\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = MLP(num_features=109,\n",
    "            num_hidden_1=100,\n",
    "            num_classes=67)\n",
    "\n",
    "\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5c0623-069d-4b7f-aa50-d728a213f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 100])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m y[i]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m### FORWARD AND BACK PROP\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m logits, probas \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(features)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     18\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     19\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_out(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2480\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2468\u001b[0m         batch_norm,\n\u001b[1;32m   2469\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2478\u001b[0m     )\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2448\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2446\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 100])"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    # pytorch is expecting minibatch of examples\n",
    "    for i in range(y.size()[0]):\n",
    "        \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = x[i].view(-1, 109).to(DEVICE)\n",
    "        targets = y[i].to(DEVICE) # This is just giving one example of y\n",
    "        # We want it to be of size (batch size) x (# of classes)\n",
    "        # Check examples of FashionMNIST dataset\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model.forward(features)\n",
    "        print(f'Target: {targets}')\n",
    "        print(f'Logits: {logits}')\n",
    "        print(f'Probabilities: {probas}')\n",
    "        cost = F.cross_entropy(torch.flatten(logits), targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## LOGGING\n",
    "        if not i % 20:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {i:03d}/{len(x):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
